{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f35df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9907ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import PneumothoraxDataset, get_train_transforms, get_val_transforms\n",
    "from utils import predict_with_tiles, dice_coefficient, iou_score\n",
    "from models.unet import UNet\n",
    "from dataset import build_file_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4349f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Paths\n",
    "    dicom_path = Path('./pneumothorax_data/dicom-images-train')\n",
    "    rle_path = Path('./pneumothorax_data/train-rle.csv')\n",
    "    save_dir = Path('./results')\n",
    "    \n",
    "    # Model\n",
    "    model_name = 'unet' #모델명 여기서 수정\n",
    "    in_channels = 3\n",
    "    n_classes = 1\n",
    "    \n",
    "    # Training\n",
    "    batch_size = 2 #수정\n",
    "    num_epochs = 1 #수정\n",
    "    learning_rate = 1e-4\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Augmentation\n",
    "    use_mirroring = False #수정\n",
    "    pad_size = 0#92\n",
    "    \n",
    "    use_tile_strategy = True\n",
    "    tile_size = 128 #512\n",
    "    tile_overlap = 92\n",
    "\n",
    "config = Config()\n",
    "config.save_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febaec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 DICOM 파일 수: 10712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "인덱싱: 100%|██████████| 10712/10712 [00:00<00:00, 1016639.92it/s]\n"
     ]
    }
   ],
   "source": [
    "file_paths_dict = build_file_paths_dict(config.dicom_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a3b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 80, Val: 20\n"
     ]
    }
   ],
   "source": [
    "train_rle = pd.read_csv(config.rle_path)\n",
    "\n",
    "all_image_ids = train_rle['ImageId'].unique()[:100]#수정\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_image_ids)\n",
    "\n",
    "split_idx = int(len(all_image_ids) * 0.8)\n",
    "train_ids = all_image_ids[:split_idx]\n",
    "val_ids = all_image_ids[split_idx:]\n",
    "\n",
    "print(f\"Train: {len(train_ids)}, Val: {len(val_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f81323d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 가능한 이미지: 80개\n",
      "\n",
      "사용 가능한 이미지: 20개\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PneumothoraxDataset(\n",
    "    image_ids=train_ids,\n",
    "    train_rle=train_rle,\n",
    "    #dicom_path=config.dicom_path,\n",
    "    file_paths_dict=file_paths_dict,\n",
    "    transform=get_train_transforms(),\n",
    "    #use_mirroring=config.use_mirroring,\n",
    "    use_mirroring=False,\n",
    "    pad_size=config.pad_size if config.use_mirroring else 0\n",
    ")\n",
    "\n",
    "val_dataset = PneumothoraxDataset(\n",
    "    image_ids=val_ids,\n",
    "    train_rle=train_rle,\n",
    "    file_paths_dict=file_paths_dict,\n",
    "    transform=get_val_transforms(),\n",
    "    use_mirroring=False,  # Validation은 mirroring 사용 안 함\n",
    "    pad_size=0\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803b26a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 명 : unet\n"
     ]
    }
   ],
   "source": [
    "print(f\"모델 명 : {config.model_name}\")\n",
    "model = UNet(in_channels=config.in_channels, n_classes=config.n_classes)\n",
    "model = model.to(config.device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "optimizer = optim.SGD(model.parameters(), momentum=0.99)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e030519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_dice = 0.0\n",
    "    \n",
    "    with tqdm(loader, desc=\"Training\") as pbar:\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Metrics\n",
    "            with torch.no_grad():\n",
    "                preds = torch.sigmoid(outputs)\n",
    "                dice = dice_coefficient(preds > 0.5, masks)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_dice += dice\n",
    "            \n",
    "            pbar.set_postfix({'loss': loss.item(), 'dice': dice})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_dice = running_dice / len(loader)\n",
    "    \n",
    "    return epoch_loss, epoch_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d442286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_dice = 0.0\n",
    "    running_iou = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(loader, desc=\"Validation\") as pbar:\n",
    "            for images, masks in pbar:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                preds = torch.sigmoid(outputs)\n",
    "                dice = dice_coefficient(preds > 0.5, masks)\n",
    "                iou = iou_score(preds > 0.5, masks)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                running_dice += dice\n",
    "                running_iou += iou\n",
    "                \n",
    "                pbar.set_postfix({'loss': loss.item(), 'dice': dice, 'iou': iou})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_dice = running_dice / len(loader)\n",
    "    epoch_iou = running_iou / len(loader)\n",
    "    \n",
    "    return epoch_loss, epoch_dice, epoch_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "best_dice = 0.0\n",
    "history = {\n",
    "    'train_loss': [], 'train_dice': [],\n",
    "    'val_loss': [], 'val_dice': [], 'val_iou': []\n",
    "}\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.num_epochs}\")\n",
    "    \n",
    "    train_loss, train_dice = train_epoch(model, train_loader, criterion, optimizer, config.device)\n",
    "    val_loss, val_dice, val_iou = validate_epoch(model, val_loader, criterion, config.device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_dice'].append(train_dice)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}, Val IoU: {val_iou:.4f}\")\n",
    "    \n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        torch.save(model.state_dict(), config.save_dir / f'best_{config.model_name}.pth')\n",
    "        print(f\"best model saved. (Dice: {best_dice:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Loss')\n",
    "\n",
    "axes[1].plot(history['train_dice'], label='Train Dice')\n",
    "axes[1].plot(history['val_dice'], label='Val Dice')\n",
    "axes[1].plot(history['val_iou'], label='Val IoU')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Metrics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.save_dir / f'{config.model_name}_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n테스트 추론 중...\")\n",
    "model.load_state_dict(torch.load(config.save_dir / f'best_{config.model_name}.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 테스트 샘플 예측 (validation set에서 샘플링)\n",
    "test_samples = val_ids[:5]  # 5개 샘플만 테스트\n",
    "\n",
    "for img_id in test_samples:\n",
    "    # Load image\n",
    "    file_path = val_dataset.file_paths[img_id]\n",
    "    import pydicom\n",
    "    dcm = pydicom.dcmread(file_path)\n",
    "    image = dcm.pixel_array\n",
    "    \n",
    "    if image.max() > 0:\n",
    "        image = image.astype(np.float32) / image.max()\n",
    "    else:\n",
    "        image = image.astype(np.float32)\n",
    "    \n",
    "    image = np.stack([image, image, image], axis=-1)\n",
    "    \n",
    "    # Predict\n",
    "    if config.use_tile_strategy:\n",
    "        prediction = predict_with_tiles(\n",
    "            model=model,\n",
    "            image=image,\n",
    "            tile_size=config.tile_size,\n",
    "            overlap=config.tile_overlap,\n",
    "            device=config.device\n",
    "        )\n",
    "    else:\n",
    "        # Simple inference\n",
    "        image_norm = (image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "        image_tensor = torch.from_numpy(image_norm).permute(2, 0, 1).unsqueeze(0).float().to(config.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor)\n",
    "            prediction = torch.sigmoid(output).cpu().numpy()[0, 0]\n",
    "    \n",
    "    # Threshold\n",
    "    binary_pred = (prediction > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Load ground truth\n",
    "    rle = train_rle[train_rle['ImageId'] == img_id][' EncodedPixels'].values[0]\n",
    "    from dataset import rle_decode\n",
    "    \n",
    "    if rle == '-1' or pd.isna(rle):\n",
    "        gt_mask = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "    else:\n",
    "        gt_mask = rle_decode(rle, 1024, 1024)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(image[:, :, 0], cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(gt_mask, cmap='gray')\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(binary_pred, cmap='gray')\n",
    "    axes[2].set_title('Prediction')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.save_dir / f'prediction_{img_id}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"\\n완료! 결과는 {config.save_dir}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998d240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
